{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Pinecone\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFDirectoryLoader(\"PDFs\")\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "text_chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pinecone_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(\"indchatpdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"indchatpdf\"\n",
    "for i, t in zip(range(len(text_chunks)), text_chunks):\n",
    "   query_result = embedding.embed_query(t.page_content)\n",
    "   index.upsert(\n",
    "   vectors=[\n",
    "        {\n",
    "            \"id\": str(i),  # Convert i to a string\n",
    "            \"values\": query_result, \n",
    "            \"metadata\": {\"text\":str(text_chunks[i].page_content)} # meta data as dic\n",
    "        }\n",
    "    ],\n",
    "    namespace=\"real\")\n",
    "   index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = 'text'\n",
    "vectorstore = Pinecone(\n",
    "    index, embedding, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "query = \"What is a Transformer?\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "input=[query],\n",
    "model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "dres = index.query(vector=xq, top_k=2, namespace='real' , include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 3750\n",
    "\n",
    "import time\n",
    "\n",
    "def retrieve(query):\n",
    "    res = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        model = \"text-embedding-ada-002\"\n",
    "    )\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    xq = res['data'][0]['embedding']\n",
    "\n",
    "    # get relevant contexts\n",
    "    contexts = []\n",
    "    time_waited = 0\n",
    "    while (len(contexts) < 3 and time_waited < 60 * 12):\n",
    "        res = index.query(vector=xq, top_k=3,namespace='real', include_metadata=True)\n",
    "        contexts = contexts + [\n",
    "            x['metadata']['text'] for x in res['matches']\n",
    "        ]\n",
    "        print(f\"Retrieved {len(contexts)} contexts, sleeping for 15 seconds...\")\n",
    "        time.sleep(15)\n",
    "        time_waited += 15\n",
    "\n",
    "    if time_waited >= 60 * 12:\n",
    "        print(\"Timed out waiting for contexts to be retrieved.\")\n",
    "        contexts = [\"No contexts retrieved. Try to answer the question yourself!\"]\n",
    "\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def complete(prompt):\n",
    "    # instructions\n",
    "    sys_prompt = \"You are a helpful assistant that always answers questions.\"\n",
    "    # query text-davinci-003\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo-0613',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return res['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 contexts, sleeping for 15 seconds...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.\\n\\nContext:\\nFigure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\n\\n---\\n\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., x n)to a sequence\\nof continuous representations z= (z1, ..., z n). Given z, the decoder then generates an output\\n\\n---\\n\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\n\\nQuestion: What is encoder in the transformer architecture\\nAnswer:'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = (\n",
    "    \"What is encoder \" +\n",
    "    \"in the transformer architecture\"\n",
    ")\n",
    "\n",
    "query_with_contexts = retrieve(query)\n",
    "query_with_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the Transformer architecture, the encoder is a stack of N=6 identical layers. Each layer consists of two sub-layers: a multi-head self-attention mechanism and a simple, position-aligned RNNs or convolution.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete(query_with_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 contexts, sleeping for 15 seconds...\n",
      "In the Transformer architecture, the encoder is a stack of N=6 identical layers. Each layer consists of two sub-layers: a multi-head self-attention mechanism and a simple, position-aligned RNNs or convolution.\n",
      "Retrieved 3 contexts, sleeping for 15 seconds...\n",
      "A decoder is a component in a neural sequence transduction model that generates an output sequence based on the continuous representations obtained from the encoder. It consists of a stack of identical layers, with each layer having two sub-layers and an additional sub-layer for multi-head attention over the output of the encoder stack. The decoder also employs residual connections and layer normalization for each sub-layer.\n",
      "Exiting\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "while True:\n",
    "  user_input = input(f\"Input Prompt: \")\n",
    "  if user_input == 'exit':\n",
    "    print('Exiting')\n",
    "    sys.exit()\n",
    "  if user_input == '':\n",
    "    continue\n",
    "  result = complete(retrieve(user_input))\n",
    "  print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
